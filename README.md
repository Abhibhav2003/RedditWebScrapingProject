# ğŸš€ Reddit Community Scraper

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge&logo=python)](https://www.python.org/)
[![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup-Web%20Scraping-brightgreen?style=for-the-badge)](https://www.crummy.com/software/BeautifulSoup/)
![Pandas](https://img.shields.io/badge/Pandas-Data%20Processing-yellow?style=for-the-badge&logo=pandas)

## ğŸ“– About

This project is a **web scraper** for extracting the **top Reddit communities**, their categories, subscriber counts, and links.  
The scraped data is then stored in an **Excel file** (`Scraped_Data.xlsx`) for further analysis.  

## âœ¨ Features

âœ… Scrapes **top Reddit communities**  
âœ… Extracts **Subreddit names, categories, subscriber count, and links**  
âœ… Saves data in a **structured Excel file**  
âœ… Uses **BeautifulSoup** for web scraping  

---

## âš¡ Installation  

Clone this repository:  
git clone https://github.com/Abhibhav2003/RedditWebScrapingProject.git


## Install Dependencies

pip install -r requirements.txt

Or you can manually install the required Libraries using pip :

pip install pandas BeautifulSoup requests


## Output
On running the Script the output will stored in a xlsx format in your present working directory.


## ğŸ› ï¸ Technologies Used
Python 3.8+
BeautifulSoup (for HTML parsing)
Requests (for fetching web pages)
Pandas (for data manipulation & saving)

## ğŸ’¡ Contributing
Want to improve this scraper? Feel free to fork the repository, create a branch, and submit a pull request! ğŸ˜Š
